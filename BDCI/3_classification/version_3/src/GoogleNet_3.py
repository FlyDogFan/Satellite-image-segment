'''Google Inception（v3）。应用于 Oxford Flowers 17 分类任务的谷歌 Inception v3 网络'''import tflearnfrom tflearn.layers.core import input_data, dropout, fully_connectedfrom tflearn.layers.conv import conv_2d, max_pool_2d, avg_pool_2dfrom tflearn.layers.normalization import batch_normalizationfrom tflearn.layers.merge_ops import mergefrom tflearn.layers.estimator import regressionimport picklefrom TData_3 import TDatafrom Param import Paramfrom PreData_3 import PreDatafrom FinalResult_2 import FinalResultimport osimport timeclass GoogleNet:    def __init__(self, class_number, input_size):        self._class_number = class_number        self._input_size = input_size        self._last_pooling = None        self._loss = None        self._network = None        self.layers()        pass    def layers(self):        network = input_data(shape=[None, self._input_size, self._input_size, 5])        con1_7_7 = conv_2d(network, 64, 7, strides=2, activation='relu', name='conv1_7_7_s2')        pool1_3_3 = max_pool_2d(con1_7_7, 3, strides=2)        pool1_3_3 = batch_normalization(pool1_3_3)        conv2_3_3_reduce = conv_2d(pool1_3_3, 64, 1, activation='relu', name='conv2_3_3_reduce')        conv2_3_3 = conv_2d(conv2_3_3_reduce, 192, 3, activation='relu', name='conv2_3_3')        conv2_3_3 = batch_normalization(conv2_3_3)        pool2_3_3 = max_pool_2d(conv2_3_3, kernel_size=3, strides=2, name='pool2_3_3_s2')        # 3a        inception_3a_1_1 = conv_2d(pool2_3_3, 64, 1, activation='relu', name='inception_3a_1_1')        inception_3a_3_3_reduce = conv_2d(pool2_3_3, 96, 1, activation='relu', name='inception_3a_3_3_reduce')        inception_3a_3_3 = conv_2d(inception_3a_3_3_reduce, 128, filter_size=3, activation='relu',                                   name='inception_3a_3_3')        inception_3a_5_5_reduce = conv_2d(pool2_3_3, 16, filter_size=1, activation='relu',                                          name='inception_3a_5_5_reduce')        inception_3a_5_5 = conv_2d(inception_3a_5_5_reduce, 32, filter_size=5, activation='relu',                                   name='inception_3a_5_5')        inception_3a_pool = max_pool_2d(pool2_3_3, kernel_size=3, strides=1, name='inception_3a_pool_1_1')        inception_3a_output = merge([inception_3a_1_1, inception_3a_3_3, inception_3a_5_5, inception_3a_pool],                                    mode='concat', axis=3)        # 3b        inception_3b_1_1 = conv_2d(inception_3a_output, 128, filter_size=1, activation='relu', name='inception_3b_1_1')        inception_3b_3_3_reduce = conv_2d(inception_3a_output, 128, filter_size=1, activation='relu',                                          name='inception_3b_3_3_reduce')        inception_3b_3_3 = conv_2d(inception_3b_3_3_reduce, 192, filter_size=3, activation='relu',                                   name='inception_3b_3_3')        inception_3b_5_5_reduce = conv_2d(inception_3a_output, 32, filter_size=1, activation='relu',                                          name='inception_3b_5_5_reduce')        inception_3b_5_5 = conv_2d(inception_3b_5_5_reduce, 96, filter_size=5, name='inception_3b_5_5')        inception_3b_pool = max_pool_2d(inception_3a_output, kernel_size=3, strides=1, name='inception_3b_pool')        inception_3b_pool_1_1 = conv_2d(inception_3b_pool, 64, filter_size=1, activation='relu',                                        name='inception_3b_pool_1_1')        inception_3b_output = merge([inception_3b_1_1, inception_3b_3_3, inception_3b_5_5, inception_3b_pool_1_1],                                    mode='concat',                                    axis=3, name='inception_3b_output')        pool3_3_3 = max_pool_2d(inception_3b_output, kernel_size=3, strides=2, name='pool3_3_3')        # 4a        inception_4a_1_1 = conv_2d(pool3_3_3, 192, filter_size=1, activation='relu', name='inception_4a_1_1')        inception_4a_3_3_reduce = conv_2d(pool3_3_3, 96, filter_size=1, activation='relu',                                          name='inception_4a_3_3_reduce')        inception_4a_3_3 = conv_2d(inception_4a_3_3_reduce, 208, filter_size=3, activation='relu',                                   name='inception_4a_3_3')        inception_4a_5_5_reduce = conv_2d(pool3_3_3, 16, filter_size=1, activation='relu',                                          name='inception_4a_5_5_reduce')        inception_4a_5_5 = conv_2d(inception_4a_5_5_reduce, 48, filter_size=5, activation='relu',                                   name='inception_4a_5_5')        inception_4a_pool = max_pool_2d(pool3_3_3, kernel_size=3, strides=1, name='inception_4a_pool')        inception_4a_pool_1_1 = conv_2d(inception_4a_pool, 64, filter_size=1, activation='relu',                                        name='inception_4a_pool_1_1')        inception_4a_output = merge([inception_4a_1_1, inception_4a_3_3, inception_4a_5_5, inception_4a_pool_1_1],                                    mode='concat', axis=3, name='inception_4a_output')        # 4b        inception_4b_1_1 = conv_2d(inception_4a_output, 160, filter_size=1, activation='relu', name='inception_4b_1_1')        inception_4b_3_3_reduce = conv_2d(inception_4a_output, 112, filter_size=1, activation='relu',                                          name='inception_4b_3_3')        inception_4b_3_3 = conv_2d(inception_4b_3_3_reduce, 224, filter_size=3, activation='relu',                                   name='inception_4b_3_3')        inception_4b_5_5_reduce = conv_2d(inception_4a_output, 24, filter_size=1, activation='relu',                                          name='inception_4b_5_5_reduce')        inception_4b_5_5 = conv_2d(inception_4b_5_5_reduce, 64, filter_size=5, activation='relu',                                   name='inception_4b_5_5')        inception_4b_pool = max_pool_2d(inception_4a_output, kernel_size=3, strides=1, name='inception_4b_pool')        inception_4b_pool_1_1 = conv_2d(inception_4b_pool, 64, filter_size=1, activation='relu',                                        name='inception_4b_pool_1_1')        inception_4b_output = merge([inception_4b_1_1, inception_4b_3_3, inception_4b_5_5, inception_4b_pool_1_1],                                    mode='concat', axis=3, name='inception_4b_output')        # 4c        inception_4c_1_1 = conv_2d(inception_4b_output, 128, filter_size=1, activation='relu', name='inception_4c_1_1')        inception_4c_3_3_reduce = conv_2d(inception_4b_output, 128, filter_size=1, activation='relu',                                          name='inception_4c_3_e_reduce')        inception_4c_3_3 = conv_2d(inception_4c_3_3_reduce, 256, filter_size=3, activation='relu',                                   name='inception_4c_3_3')        inception_4c_5_5_reduce = conv_2d(inception_4b_output, 24, filter_size=1, activation='relu',                                          name='inception_4c_5_5_reduce')        inception_4c_5_5 = conv_2d(inception_4c_5_5_reduce, 64, filter_size=5, activation='relu',                                   name='inception_4c_5_5')        inception_4c_pool = max_pool_2d(inception_4b_output, kernel_size=3, strides=1)        inception_4c_pool_1_1 = conv_2d(inception_4c_pool, 64, filter_size=1, activation='relu',                                        name='inception_4c_pool_1_1')        inception_4c_output = merge([inception_4c_1_1, inception_4c_3_3, inception_4c_5_5, inception_4c_pool_1_1],                                    mode='concat', axis=3, name='inception_4c_output')        # 4d        inception_4d_1_1 = conv_2d(inception_4c_output, 112, filter_size=1, activation='relu', name='inception_4d_1_1')        inception_4d_3_3_reduce = conv_2d(inception_4c_output, 144, filter_size=1, activation='relu',                                          name='inception_4d_3_3_reduce')        inception_4d_3_3 = conv_2d(inception_4d_3_3_reduce, 288, filter_size=3, activation='relu',                                   name='inception_4d_3_3')        inception_4d_5_5_reduce = conv_2d(inception_4c_output, 32, filter_size=1, activation='relu',                                          name='inception_4d_5_5_reduce')        inception_4d_5_5 = conv_2d(inception_4d_5_5_reduce, 64, filter_size=5, activation='relu',                                   name='inception_4d_5_5')        inception_4d_pool = max_pool_2d(inception_4c_output, kernel_size=3, strides=1, name='inception_4d_pool')        inception_4d_pool_1_1 = conv_2d(inception_4d_pool, 64, filter_size=1, activation='relu',                                        name='inception_4d_pool_1_1')        inception_4d_output = merge([inception_4d_1_1, inception_4d_3_3, inception_4d_5_5, inception_4d_pool_1_1],                                    mode='concat', axis=3, name='inception_4d_output')        # 4e        inception_4e_1_1 = conv_2d(inception_4d_output, 256, filter_size=1, activation='relu', name='inception_4e_1_1')        inception_4e_3_3_reduce = conv_2d(inception_4d_output, 160, filter_size=1, activation='relu',                                          name='inception_4e_3_3_reduce')        inception_4e_3_3 = conv_2d(inception_4e_3_3_reduce, 320, filter_size=3, activation='relu',                                   name='inception_4e_3_3')        inception_4e_5_5_reduce = conv_2d(inception_4d_output, 32, filter_size=1, activation='relu',                                          name='inceptin_4e_5_5_reduce')        inception_4e_5_5 = conv_2d(inception_4e_5_5_reduce, 128, filter_size=5, activation='relu',                                   name='inception_4e_5_5')        inception_4e_pool = max_pool_2d(inception_4d_output, kernel_size=3, strides=1, name='inception_4e_pool')        inception_4e_pool_1_1 = conv_2d(inception_4e_pool, 128, filter_size=1, activation='relu',                                        name='inception_4e_pool_1_1')        inception_4e_output = merge([inception_4e_1_1, inception_4e_3_3, inception_4e_5_5, inception_4e_pool_1_1],                                    mode='concat', axis=3, name='inception_4e_output')        pool4_3_3 = max_pool_2d(inception_4e_output, kernel_size=3, strides=2, name='pool4_3_3')        # 5a        inception_5a_1_1 = conv_2d(pool4_3_3, 256, filter_size=1, activation='relu', name='inception_5a_1_1')        inception_5a_3_3_reduce = conv_2d(pool4_3_3, 160, filter_size=1, activation='relu',                                          name='inception_5a_3_3_reduce')        inception_5a_3_3 = conv_2d(inception_5a_3_3_reduce, 320, filter_size=3, activation='relu',                                   name='inception_5a_3_3')        inception_5a_5_5_reduce = conv_2d(pool4_3_3, 32, filter_size=1, activation='relu',                                          name='inception_5a_5_5_reduce')        inception_5a_5_5 = conv_2d(inception_5a_5_5_reduce, 128, filter_size=5, activation='relu',                                   name='inception_5a_5_5')        inception_5a_pool = max_pool_2d(pool4_3_3, kernel_size=3, strides=1, name='inception_5a_pool')        inception_5a_pool_1_1 = conv_2d(inception_5a_pool, 128, filter_size=1, activation='relu',                                        name='inception_5a_pool_1_1')        inception_5a_output = merge([inception_5a_1_1, inception_5a_3_3, inception_5a_5_5, inception_5a_pool_1_1],                                    mode='concat', axis=3, name='inception_5a_output')        # 5b        inception_5b_1_1 = conv_2d(inception_5a_output, 384, filter_size=1, activation='relu', name='inception_5b_1_1')        inception_5b_3_3_reduce = conv_2d(inception_5a_output, 192, filter_size=1, activation='relu',                                          name='inception_5b_3_3_reduce')        inception_5b_3_3 = conv_2d(inception_5b_3_3_reduce, 384, filter_size=3, activation='relu',                                   name='inception_5b_3_3')        inception_5b_5_5_reduce = conv_2d(inception_5a_output, 48, filter_size=1, activation='relu',                                          name='inception_5b_5_5_reduce')        inception_5b_5_5 = conv_2d(inception_5b_5_5_reduce, 128, filter_size=5, activation='relu',                                   name='inception_5b_5_5')        inception_5b_pool = max_pool_2d(inception_5a_output, kernel_size=3, strides=1, name='inception_5b_pool')        inception_5b_pool_1_1 = conv_2d(inception_5b_pool, 128, filter_size=1, activation='relu',                                        name='inception_5b_pool_1_1')        inception_5b_output = merge([inception_5b_1_1, inception_5b_3_3, inception_5b_5_5, inception_5b_pool_1_1],                                    mode='concat', axis=3, name='inception_5b_output')        pool5_7_7 = avg_pool_2d(inception_5b_output, kernel_size=7, strides=1)        pool5_7_7 = dropout(pool5_7_7, 0.4)        self._last_pooling = pool5_7_7        self._loss = fully_connected(self._last_pooling, self._class_number, activation='softmax')        self._network = regression(self._loss, optimizer='adam', loss='categorical_crossentropy', learning_rate=0.001)        pass    def loss(self):        return self._loss    def regression(self):        return self._network    passclass Runner:    def __init__(self, network, data_file_name, model_dir, model_name, n_epoch, batch_size,                 image_size=None, is_training=True,                 test_image_files=None, test_sketch_files=None, test_area_files=None,                 result_pkl_path=None):        # network        self._network = network        self._is_training = is_training        # data        self._data_file_name = data_file_name        self._input_X, self._input_Y = self.get_data(self._data_file_name)        self._test_image_files = test_image_files        self._test_sketch_files = test_sketch_files        self._test_area_files = test_area_files        self._result_pkl_path = self.new_dir(result_pkl_path)        self._image_size = image_size        # model        self._model = tflearn.DNN(self._network)        self._model_dir = model_dir        self._model_name = model_name        self._n_epoch = n_epoch        self._batch_size = batch_size        pass    def run(self, test_batch_size, stripe):        if self._is_training:            self.train()            self.save_model()        self.prediction(test_batch_size, stripe)        pass    # data    @staticmethod    def get_data(data_file):        with open("{}.pkl".format(data_file), 'rb') as f: data = pickle.load(f)        return data['X'],  data["Y"]    def train(self):        # train        self._model.fit(self._input_X, self._input_Y, n_epoch=self._n_epoch, validation_set=0.2,                        shuffle=True, show_metric=True, batch_size=self._batch_size, snapshot_step=200,                        snapshot_epoch=False, run_id=self._model_name)        pass    def save_model(self):        self._model.save("{}/{}.tfl".format(self._model_dir, self._model_name))        pass    def prediction(self, batch_size, stripe):        if not self._is_training:            self._model.load("{}/{}.tfl".format(self._model_dir, self._model_name))        # data        for index, image_file in enumerate(self._test_image_files):            # data            test_data = TData(self._image_size, batch_size=batch_size, stripe=stripe, image_file=image_file,                              sketch_file=self._test_sketch_files[index], area_file=self._test_area_files[index])            # prediction            labels = []            positions = []            for x in range(test_data.batch_all_number):                if x % 100 == 0:                    print("{} time = {}, x = {}/{}".format(index, time.strftime("%H:%M:%S", time.localtime()),                                                           x, test_data.batch_all_number))                datas, poss = test_data.get_batch_data(x)                label = self._model.predict_label(datas)                labels.extend([now_label[0] for now_label in label])                positions.extend(poss)                pass            # save            with open("{}/result_{}.pkl".format(self._result_pkl_path, index),"wb") as f:                pickle.dump({"labels": labels, "positions": positions}, f)        pass    @staticmethod    def new_dir(path):        if not os.path.exists(path):            os.makedirs(path)        return path    passif __name__ == '__main__':    name = Param.name    size = Param.image_size    test_stripe = Param.test_stripe    # 1    # pre data    PreData(images=["../data/CCF-training/1.png",                    "../data/CCF-training/2.png"],            labels=["../data/CCF-training/1_class.png",                    "../data/CCF-training/2_class.png"],            sketchs=["../data/sketch_area/1.0_1.7/train_1_sketch.bmp",                     "../data/sketch_area/1.0_1.7/train_2_sketch.bmp"],            areas=["../data/sketch_area/1.0_1.7/train_1_sketch_area.bmp",                   "../data/sketch_area/1.0_1.7/train_2_sketch_area.bmp"],            stripe=20, crop_size=size, ratio=0, number=5000,            result_pkl="../dist/{}/data/train.pkl".format(name),            need_label=[1, 2, 3, 4])    # 2    # train    model_dir = "../dist/{}/model".format(name)    model_name = "train"    data_file_name = "../dist/{}/data/train".format(name)    result_pkl_path = "../dist/{}/result".format(name)    gooleNet = GoogleNet(class_number=4, input_size=size)    network = gooleNet.regression()    run = Runner(network, data_file_name, model_dir, model_name, n_epoch=50, batch_size=64, image_size=size,                 test_image_files=["../data/CCF-testing/1.png",                                   "../data/CCF-testing/2.png",                                   "../data/CCF-testing/3.png"],                 test_sketch_files=["../data/sketch_area/1.0_1.7/1_sketch.bmp",                                    "../data/sketch_area/1.0_1.7/2_sketch.bmp",                                    "../data/sketch_area/1.0_1.7/3_sketch.bmp"],                 test_area_files=["../data/sketch_area/1.0_1.7/1_sketch_area.bmp",                                  "../data/sketch_area/1.0_1.7/2_sketch_area.bmp",                                  "../data/sketch_area/1.0_1.7/3_sketch_area.bmp"],                 result_pkl_path=result_pkl_path)    run.run(test_batch_size=256, stripe=test_stripe)    # 3    # final result    name = Param.name    stripe = Param.test_stripe    for index in range(3):        labels, positions = FinalResult.load_data("../dist/{}/result/result_{}.pkl".format(name, index))        new_labels = FinalResult.padding_data(labels, positions, stripe, 5190, 5204)        FinalResult.write_color(new_labels, "../dist/{}/result/result_{}.bmp".format(name, index + 1))        FinalResult.to_csv(new_labels, index + 1, name)        pass    pass